# -*- coding: utf-8 -*-
"""PROJECT-PHASE-l.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14ze307mVofz1alN7gMtYdoMEj8A6I9vj

#U
"""

import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import pandas as pd

# Load and clean the dataset
file_path = 'dataset bp1.xlsx'
cleaned_data = pd.read_excel(file_path, skiprows=1)
data_cleaned = cleaned_data[['time', 'u']].dropna()

# Prepare data
X = data_cleaned['time'].values.reshape(-1, 1)
y = data_cleaned['u'].values.reshape(-1, 1)

# Split the data into 80% training and 20% validation
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the PINN model
class PINN(tf.keras.Model):
    def __init__(self):
        super(PINN, self).__init__()
        self.hidden1 = tf.keras.layers.Dense(20, activation='tanh')
        self.hidden2 = tf.keras.layers.Dense(20, activation='tanh')
        self.hidden3 = tf.keras.layers.Dense(20, activation='tanh')
        self.output_layer = tf.keras.layers.Dense(1, activation=None)

    def call(self, x):
        x = self.hidden1(x)
        x = self.hidden2(x)
        x = self.hidden3(x)
        return self.output_layer(x)

# Instantiate the model
pinn_model = PINN()

# Define the custom loss function to enforce the ODE (du/dt)
def physics_loss(y_true, y_pred):
    # Assume the input X_train corresponds to the same batch size as y_true
    t_batch = tf.convert_to_tensor(y_true[:, 0], dtype=tf.float32)  # Matching batch size of y_true
    t_batch = tf.reshape(t_batch, (-1, 1))  # Reshape to ensure it has 2 dimensions

    with tf.GradientTape() as tape:
        tape.watch(t_batch)
        u_pred = pinn_model(t_batch)
        du_dt_pred = tape.gradient(u_pred, t_batch)  # Compute du/dt

    # Physics loss = (du/dt - predicted du/dt)^2
    physics_loss = tf.reduce_mean(tf.square(du_dt_pred - y_true))

    # Also include the prediction loss (prediction vs ground truth u)
    prediction_loss = tf.reduce_mean(tf.square(y_pred - y_true))

    # Total loss = prediction loss + physics loss
    return prediction_loss + physics_loss

# Compile the model
pinn_model.compile(optimizer='adam', loss=physics_loss)

# Train the model
history = pinn_model.fit(X_train, y_train, epochs=1000, validation_data=(X_val, y_val), batch_size=32, verbose=0)

# Plot the training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Make predictions
y_pred = pinn_model.predict(X_val)

# Plot true vs predicted values
plt.scatter(X_val, y_val, label='True Values')
plt.scatter(X_val, y_pred, label='Predicted Values')
plt.xlabel('Time')
plt.ylabel('u')
plt.legend()
plt.show()

"""#V"""

import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import pandas as pd

# Load and clean the dataset
file_path = 'dataset bp1.xlsx'
cleaned_data = pd.read_excel(file_path, skiprows=1)
data_cleaned = cleaned_data[['time', 'v']].dropna()  # Use 'v' instead of 'u'

# Prepare data
X = data_cleaned['time'].values.reshape(-1, 1)
y = data_cleaned['v'].values.reshape(-1, 1)  # Target is now 'v'

# Split the data into 80% training and 20% validation
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the PINN model
class PINN(tf.keras.Model):
    def __init__(self):
        super(PINN, self).__init__()
        self.hidden1 = tf.keras.layers.Dense(20, activation='tanh')
        self.hidden2 = tf.keras.layers.Dense(20, activation='tanh')
        self.hidden3 = tf.keras.layers.Dense(20, activation='tanh')
        self.output_layer = tf.keras.layers.Dense(1, activation=None)

    def call(self, x):
        x = self.hidden1(x)
        x = self.hidden2(x)
        x = self.hidden3(x)
        return self.output_layer(x)

# Instantiate the model
pinn_model = PINN()

# Define the custom loss function to enforce the ODE (dv/dt)
def physics_loss(y_true, y_pred):
    # Assume the input X_train corresponds to the same batch size as y_true
    t_batch = tf.convert_to_tensor(y_true[:, 0], dtype=tf.float32)  # Matching batch size of y_true
    t_batch = tf.reshape(t_batch, (-1, 1))  # Reshape to ensure it has 2 dimensions

    with tf.GradientTape() as tape:
        tape.watch(t_batch)
        v_pred = pinn_model(t_batch)
        dv_dt_pred = tape.gradient(v_pred, t_batch)  # Compute dv/dt

    # Physics loss = (dv/dt - predicted dv/dt)^2
    physics_loss = tf.reduce_mean(tf.square(dv_dt_pred - y_true))

    # Also include the prediction loss (prediction vs ground truth v)
    prediction_loss = tf.reduce_mean(tf.square(y_pred - y_true))

    # Total loss = prediction loss + physics loss
    return prediction_loss + physics_loss

# Compile the model
pinn_model.compile(optimizer='adam', loss=physics_loss)

# Train the model
history = pinn_model.fit(X_train, y_train, epochs=1000, validation_data=(X_val, y_val), batch_size=32, verbose=0)

# Plot the training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Make predictions
y_pred = pinn_model.predict(X_val)

# Plot true vs predicted values
plt.scatter(X_val, y_val, label='True Values')
plt.scatter(X_val, y_pred, label='Predicted Values')
plt.xlabel('Time')
plt.ylabel('v')  # Update the label to 'v'
plt.legend()
plt.show()

"""#PSI"""

import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import pandas as pd

# Load and clean the dataset
file_path = 'dataset bp1.xlsx'
cleaned_data = pd.read_excel(file_path, skiprows=1)
data_cleaned = cleaned_data[['time', 'psi']].dropna()  # Use 'psi' instead of 'v'

# Prepare data
X = data_cleaned['time'].values.reshape(-1, 1)
y = data_cleaned['psi'].values.reshape(-1, 1)  # Target is now 'psi'

# Split the data into 80% training and 20% validation
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the PINN model
class PINN(tf.keras.Model):
    def __init__(self):
        super(PINN, self).__init__()
        self.hidden1 = tf.keras.layers.Dense(20, activation='tanh')
        self.hidden2 = tf.keras.layers.Dense(20, activation='tanh')
        self.hidden3 = tf.keras.layers.Dense(20, activation='tanh')
        self.output_layer = tf.keras.layers.Dense(1, activation=None)

    def call(self, x):
        x = self.hidden1(x)
        x = self.hidden2(x)
        x = self.hidden3(x)
        return self.output_layer(x)

# Instantiate the model
pinn_model = PINN()

# Define the custom loss function to enforce the ODE (dψ/dt)
def physics_loss(y_true, y_pred):
    # Assume the input X_train corresponds to the same batch size as y_true
    t_batch = tf.convert_to_tensor(y_true[:, 0], dtype=tf.float32)  # Matching batch size of y_true
    t_batch = tf.reshape(t_batch, (-1, 1))  # Reshape to ensure it has 2 dimensions

    with tf.GradientTape() as tape:
        tape.watch(t_batch)
        psi_pred = pinn_model(t_batch)
        dpsi_dt_pred = tape.gradient(psi_pred, t_batch)  # Compute dψ/dt

    # Physics loss = (dψ/dt - predicted dψ/dt)^2
    physics_loss = tf.reduce_mean(tf.square(dpsi_dt_pred - y_true))

    # Also include the prediction loss (prediction vs ground truth ψ)
    prediction_loss = tf.reduce_mean(tf.square(y_pred - y_true))

    # Total loss = prediction loss + physics loss
    return prediction_loss + physics_loss

# Compile the model
pinn_model.compile(optimizer='adam', loss=physics_loss)

# Train the model
history = pinn_model.fit(X_train, y_train, epochs=1000, validation_data=(X_val, y_val), batch_size=32, verbose=0)

# Plot the training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Make predictions
y_pred = pinn_model.predict(X_val)

# Plot true vs predicted values
plt.scatter(X_val, y_val, label='True Values')
plt.scatter(X_val, y_pred, label='Predicted Values')
plt.xlabel('Time')
plt.ylabel('psi')  # Update the label to 'psi'
plt.legend()
plt.show()

"""#R"""

import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import pandas as pd

# Load and clean the dataset
file_path = 'dataset bp1.xlsx'
cleaned_data = pd.read_excel(file_path, skiprows=1)
data_cleaned = cleaned_data[['time', 'r']].dropna()  # Use 'r' instead of 'psi' or 'v'

# Prepare data
X = data_cleaned['time'].values.reshape(-1, 1)  # Reshape to ensure 2D
y = data_cleaned['r'].values.reshape(-1, 1)  # Target is now 'r'

# Split the data into 80% training and 20% validation
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the PINN model
class PINN(tf.keras.Model):
    def __init__(self):
        super(PINN, self).__init__()
        self.hidden1 = tf.keras.layers.Dense(20, activation='tanh')
        self.hidden2 = tf.keras.layers.Dense(20, activation='tanh')
        self.hidden3 = tf.keras.layers.Dense(20, activation='tanh')
        self.output_layer = tf.keras.layers.Dense(1, activation=None)

    def call(self, x):
        x = tf.expand_dims(x, axis=-1)  # Ensure input is 2D
        x = self.hidden1(x)
        x = self.hidden2(x)
        x = self.hidden3(x)
        return self.output_layer(x)

# Instantiate the model
pinn_model = PINN()

# Define the custom loss function to enforce the ODE (dr/dt)
def physics_loss(y_true, y_pred):
    # Create a tensor for the time values corresponding to y_true
    t_batch = tf.convert_to_tensor(y_true[:, 0], dtype=tf.float32)  # Use the time values from y_true

    with tf.GradientTape() as tape:
        tape.watch(t_batch)  # Watch time for differentiation
        r_pred = pinn_model(t_batch)  # Get the predicted r for the batch
        dr_dt_pred = tape.gradient(r_pred, t_batch)  # Compute the predicted derivative dr/dt

    # Physics loss = (dr/dt - actual dr/dt from the dataset)^2
    # Placeholder for actual dr/dt values if needed
    actual_dr_dt = tf.zeros_like(dr_dt_pred)  # Replace with actual values if available
    physics_loss_value = tf.reduce_mean(tf.square(dr_dt_pred - actual_dr_dt))

    # Prediction loss = (r_pred - actual r from the dataset)^2
    prediction_loss_value = tf.reduce_mean(tf.square(y_pred - y_true))

    # Total loss = prediction loss + physics loss
    total_loss = prediction_loss_value + physics_loss_value

    return total_loss

# Compile the model
pinn_model.compile(optimizer='adam', loss=physics_loss)

# Train the model
history = pinn_model.fit(X_train, y_train, epochs=1000, validation_data=(X_val, y_val), batch_size=32, verbose=0)

# Plot the training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Make predictions
y_pred = pinn_model.predict(X_val)

# Plot true vs predicted values
plt.scatter(X_val, y_val, label='True Values', color='blue')
plt.scatter(X_val, y_pred, label='Predicted Values', color='orange')
plt.xlabel('Time')
plt.ylabel('r')  # Update the label to 'r'
plt.legend()
plt.show()

"""#R"""

import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import pandas as pd

# Load and clean the dataset
file_path = 'dataset bp1.xlsx'
cleaned_data = pd.read_excel(file_path, skiprows=1)
data_cleaned = cleaned_data[['time', 'r']].dropna()  # Use 'r' instead of 'psi' or 'v'

# Prepare data
X = data_cleaned['time'].values.reshape(-1, 1)  # Reshape to ensure 2D
y = data_cleaned['r'].values.reshape(-1, 1)  # Target is now 'r'

# Split the data into 80% training and 20% validation
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the PINN model
class PINN(tf.keras.Model):
    def __init__(self):
        super(PINN, self).__init__()
        self.hidden1 = tf.keras.layers.Dense(20, activation='tanh')
        self.hidden2 = tf.keras.layers.Dense(20, activation='tanh')
        self.hidden3 = tf.keras.layers.Dense(20, activation='tanh')
        self.output_layer = tf.keras.layers.Dense(1, activation=None)

    def call(self, x):
        x = tf.expand_dims(x, axis=-1)  # Ensure input is 2D
        x = self.hidden1(x)
        x = self.hidden2(x)
        x = self.hidden3(x)
        return self.output_layer(x)

# Instantiate the model
pinn_model = PINN()

# Define the custom loss function to enforce the ODE (dr/dt)
def physics_loss(y_true, y_pred):
    # Create a tensor for the time values corresponding to y_true
    t_batch = tf.convert_to_tensor(y_true[:, 0], dtype=tf.float32)  # Use the time values from y_true

    with tf.GradientTape() as tape:
        tape.watch(t_batch)  # Watch time for differentiation
        r_pred = pinn_model(t_batch)  # Get the predicted r for the batch
        dr_dt_pred = tape.gradient(r_pred, t_batch)  # Compute the predicted derivative dr/dt

    # Physics loss = (dr/dt - actual dr/dt from the dataset)^2
    # Placeholder for actual dr/dt values if needed
    actual_dr_dt = tf.zeros_like(dr_dt_pred)  # Replace with actual values if available
    physics_loss_value = tf.reduce_mean(tf.square(dr_dt_pred - actual_dr_dt))

    # Prediction loss = (r_pred - actual r from the dataset)^2
    prediction_loss_value = tf.reduce_mean(tf.square(y_pred - y_true))

    # Total loss = prediction loss + physics loss
    total_loss = prediction_loss_value + physics_loss_value

    return total_loss

# Compile the model
pinn_model.compile(optimizer='adam', loss=physics_loss)

# Train the model for 50 epochs
history = pinn_model.fit(X_train, y_train, epochs=1000, validation_data=(X_val, y_val), batch_size=32, verbose=0)

# Display loss values without plotting
training_loss = history.history['loss']
validation_loss = history.history['val_loss']

# Print the loss values
print("Training Loss Values:")
for epoch, loss in enumerate(training_loss):
    print(f"Epoch {epoch + 1}: Training Loss = {loss:.4f}")

print("\nValidation Loss Values:")
for epoch, loss in enumerate(validation_loss):
    print(f"Epoch {epoch + 1}: Validation Loss = {loss:.4f}")

# Make predictions
y_pred = pinn_model.predict(X_val)

# Plot true vs predicted values
plt.scatter(X_val, y_val, label='True Values', color='blue')
plt.scatter(X_val, y_pred, label='Predicted Values', color='orange')
plt.xlabel('Time')
plt.ylabel('r')  # Update the label to 'r'
plt.legend()
plt.show()